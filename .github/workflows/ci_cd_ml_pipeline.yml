name: CD/CD for the ml-pipeline that builds all the pipeline modules and pushes them to the private PyPI registry. From where Airflow will install the latest versions and use them in the next run.

on:
  push:
    paths-ignore:
      - 'app-api/'
      - 'app-frontend/'
      - '**/*.yml'
      - '**/*.md'
    branches: [ "main" ]
    
env:
  AWS_ACCESS_KEY_ID: '${{ secrets.AWS_ACCESS_KEY_ID }}'
  AWS_SECRET_ACCESS_KEY: '${{ secrets.AWS_SECRET_ACCESS_KEY }}'
  ML_PIPELINE_INSTANCE_IP: '${{ secrets.INSTANCE_IP }}'
  INSTANCE_USER: '${{ secrets.INSTANCE_USER }}'

jobs:
  ci_cd:
    runs-on: ubuntu-latest
    steps:
      - uses: 'actions/checkout@v3'

      - name: 'Configure AWS credentials'
        run: |
          echo "[default]" >> $HOME/.aws/credentials
          echo "aws_access_key_id=${{ env.AWS_ACCESS_KEY_ID }}" >> $HOME/.aws/credentials
          echo "aws_secret_access_key=${{ env.AWS_SECRET_ACCESS_KEY }}" >> $HOME/.aws/credentials
          
      - name: 'SSH into EC2 instance and execute deployment script'
        uses: 'appleboy/ssh-action@master'
        with:
          host: ${{ env.INSTANCE_IP }}
          username: ${{ env.INSTANCE_USER }}
          key: ${{ secrets.SSH_PRIVATE_KEY }}
          script: |
            cd ~/energy-forecasting
            git pull
            sh deploy/ml-pipeline.sh
